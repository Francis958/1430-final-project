{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c41ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/fer2013.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_dict = {0:\"Angry\", 1:\"Disgust\", 2: \"Fear\", 3: \"Happy\", 4: \"Sad\", 5:\"Surprise\", 6:\"Neutral\"}\n",
    "#0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c338f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining PublicTest and PrivateTest to the whole testing set\n",
    "df_training = df[df[\"Usage\"] == \"Training\"]\n",
    "df_validation = df[df[\"Usage\"] == \"PublicTest\"]\n",
    "df_testing = df[df[\"Usage\"] == \"PrivateTest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e52504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training set and testing set as csv file for the purpose of futher use\n",
    "# Uncomment commands below if you need to save these files\n",
    "# df_training.to_csv(\"data/train.csv\", index = False)\n",
    "# df_validation.to_csv(\"data/test.csv\", index = False)\n",
    "# df_testing.to_csv(\"data/validation.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inputs and labels for the training set\n",
    "def get_inputs_labels(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    inputs = [np.array(df[\"pixels\"][i].split(\" \")).astype(int) for i in range(df.shape[0])]\n",
    "    labels = [df[\"emotion\"][i] for i in range(df.shape[0])]\n",
    "    assert len(inputs) == len(labels), \"inputs and labels should have the same length.\"\n",
    "    return np.array(inputs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8eca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation and Preprocessing\n",
    "def training_testing_prep(training_file_path, validation_file_path, testing_file_path):\n",
    "    image_size = 48\n",
    "    training_inputs1, training_labels = get_inputs_labels(training_file_path)\n",
    "    validation_inputs1, validation_labels = get_inputs_labels(validation_file_path)\n",
    "    testing_inputs1, testing_labels = get_inputs_labels(testing_file_path)\n",
    "    \n",
    "    training_inputs = training_inputs1.reshape(training_inputs1.shape[0], image_size, image_size, 1)\n",
    "    ver_lst = [[]]\n",
    "    for i in range(len(training_inputs)):\n",
    "        flip = [list(np.concatenate(training_inputs[i,::-1,:,0]))]\n",
    "        ver_lst += flip\n",
    "    ver_ary = np.array(ver_lst[1:])\n",
    "    training_inputs1 = np.concatenate((training_inputs1, ver_ary), axis = 0)\n",
    "    training_inputs = training_inputs1.reshape(training_inputs1.shape[0], image_size, image_size, 1)\n",
    "\n",
    "    \n",
    "    validation_inputs = validation_inputs1.reshape(validation_inputs1.shape[0], image_size, image_size, 1)\n",
    "    ver_lst = [[]]\n",
    "    for i in range(len(validation_inputs)):\n",
    "        flip = [list(np.concatenate(validation_inputs[i,::-1,:,0]))]\n",
    "        ver_lst += flip\n",
    "    ver_ary = np.array(ver_lst[1:])\n",
    "    validation_inputs1 = np.concatenate((validation_inputs1, ver_ary), axis = 0)\n",
    "    validation_inputs = validation_inputs1.reshape(validation_inputs1.shape[0], image_size, image_size, 1)\n",
    "    \n",
    "    \n",
    "    testing_inputs = testing_inputs1.reshape(testing_inputs1.shape[0], image_size, image_size, 1)\n",
    "    ver_lst = [[]]\n",
    "    for i in range(len(testing_inputs)):\n",
    "        flip = [list(np.concatenate(testing_inputs[i,::-1,:,0]))]\n",
    "        ver_lst += flip\n",
    "    ver_ary = np.array(ver_lst[1:])\n",
    "    testing_inputs1 = np.concatenate((testing_inputs1, ver_ary), axis = 0)\n",
    "    testing_inputs = testing_inputs1.reshape(testing_inputs1.shape[0], image_size, image_size, 1)\n",
    "    \n",
    "    training_labels = tf.one_hot(training_labels, 7, dtype=tf.float32)\n",
    "    training_labels = tf.convert_to_tensor(np.concatenate((training_labels, training_labels), axis = 0), dtype=tf.float32)\n",
    "    \n",
    "    validation_labels = tf.one_hot(validation_labels, 7, dtype=tf.float32)\n",
    "    validation_labels = tf.convert_to_tensor(np.concatenate((validation_labels, validation_labels), axis = 0), dtype=tf.float32)\n",
    "    \n",
    "    testing_labels = tf.one_hot(testing_labels, 7, dtype=tf.float32)\n",
    "    testing_labels = tf.convert_to_tensor(np.concatenate((testing_labels, testing_labels), axis = 0), dtype=tf.float32)\n",
    "    \n",
    "    return training_inputs, training_labels, validation_inputs, validation_labels, testing_inputs, testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ab31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs, training_labels, validation_inputs, validation_labels, testing_inputs, testing_label = training_testing_prep(\"data/train.csv\", \"data/validation.csv\", \"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8500e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(20,10))\n",
    "for i in range(1, 13):\n",
    "    plt.subplot(4,3,i)\n",
    "    plt.imshow(training_inputs[i, :, :, 0], cmap=\"gray\")\n",
    "    plt.text(60, 25, emotions_dict[list(training_labels[i].numpy()).index(1.0)], ha = \"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011f9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(20,10))\n",
    "for i in range(1, 13):\n",
    "    plt.subplot(4,3,i)\n",
    "    plt.imshow(training_inputs[28709 + i, :, :, 0], cmap=\"gray\")\n",
    "    plt.text(60, 25, emotions_dict[list(training_labels[28709 + i].numpy()).index(1.0)], ha = \"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56c9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bff1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
